{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import dlc_practical_prologue as prologue\n",
    "from importlib import reload\n",
    "reload(prologue)\n",
    "from dlc_practical_prologue import *\n",
    "import Module, modules, optimizers, helpers\n",
    "reload(Module)\n",
    "reload(modules)\n",
    "reload(helpers)\n",
    "from modules import *\n",
    "from helpers import *\n",
    "from optimizers import *\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "train_input, train_target, train_classes, test_input, test_target, test_classes = \\\n",
    "       load_random_datasets()\n",
    "\n",
    "input = torch.Tensor([[2., 4., 6.], [1., 4., 6.], [0.5, 3., 2.], [4.3, 4., 5.],\n",
    "                      [1.3, 4.1, 6.4], [1.4, 4.1, 6.5], [5, 4., 6.]])\n",
    "target = torch.Tensor([[2], [1], [1.1], [3], [1.2], [1.21], [3.4]])\n",
    "nb_epochs = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standalone Linear Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.4593, -0.5606, -0.0493]])\n",
      "Parameter containing:\n",
      "tensor([0.8749])\n"
     ]
    }
   ],
   "source": [
    "model_lin = Linear('fc1', 3, 1)\n",
    "print_parameters_as_torch(model_lin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.4593, -0.5606, -0.0493]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.8749], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "torch.set_grad_enabled(True)\n",
    "model_lin_torch = nn.Linear(3, 1)\n",
    "set_initial_parameters(model_lin, model_lin_torch)\n",
    "for param in model_lin_torch.parameters():\n",
    "    print(param)\n",
    "del nn\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "def hook(module, grad_input, grad_output):\n",
    "    for grad in grad_output:\n",
    "        print(\"grad_output = \", grad_output[0].t())\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e = 0, loss = 22.67716, grad_output = tensor([[-1.3090, -0.8920, -0.6385, -1.8825, -1.0102, -1.0276, -2.1027]])\n",
      "e = 1, loss = 1.74668, grad_output = tensor([[ 0.1117,  0.4567,  0.0066, -0.4381,  0.4269,  0.4309, -0.4661]])\n",
      "e = 2, loss = 1.55039, grad_output = tensor([[ 0.0306,  0.3688, -0.0330, -0.4922,  0.3359,  0.3394, -0.5268]])\n",
      "e = 3, loss = 1.42432, grad_output = tensor([[ 0.0297,  0.3581, -0.0359, -0.4676,  0.3268,  0.3310, -0.4984]])\n",
      "e = 4, loss = 1.30902, grad_output = tensor([[ 0.0247,  0.3439, -0.0404, -0.4481,  0.3140,  0.3188, -0.4758]])\n",
      "\n",
      "e = 0, loss = 22.67716\n",
      "grad_output =  tensor([[-1.3090, -0.8920, -0.6385, -1.8825, -1.0102, -1.0276, -2.1027]])\n",
      "e = 1, loss = 1.74668\n",
      "grad_output =  tensor([[ 0.1117,  0.4567,  0.0066, -0.4381,  0.4269,  0.4309, -0.4661]])\n",
      "e = 2, loss = 1.55039\n",
      "grad_output =  tensor([[ 0.0306,  0.3688, -0.0330, -0.4922,  0.3359,  0.3394, -0.5268]])\n",
      "e = 3, loss = 1.42432\n",
      "grad_output =  tensor([[ 0.0297,  0.3581, -0.0359, -0.4676,  0.3268,  0.3310, -0.4984]])\n",
      "e = 4, loss = 1.30902\n",
      "grad_output =  tensor([[ 0.0247,  0.3439, -0.0404, -0.4481,  0.3140,  0.3188, -0.4758]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x7f9a283b7278>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion_lin = MSELoss()\n",
    "optimizer_lin = SGD(model_lin, lr=0.01)\n",
    "\n",
    "for e in range(nb_epochs):\n",
    "    optimizer_lin.zero_grad()\n",
    "    output_lin = model_lin(input)\n",
    "    loss_lin = criterion_lin(output_lin, target)\n",
    "    grad_output_lin = criterion_lin.backward()\n",
    "    print(\"e = {}, loss = {}, grad_output = {}\".format(e, round(loss_lin.item(), 5), grad_output_lin.t()))\n",
    "    model_lin.backward(grad_output_lin)\n",
    "    optimizer_lin.step(loss_lin)\n",
    " \n",
    "print()\n",
    "from torch import nn\n",
    "torch.set_grad_enabled(True)\n",
    "    \n",
    "model_lin_torch.register_backward_hook(hook)     \n",
    "criterion_lin_torch = nn.MSELoss()\n",
    "optimizer_lin_torch = torch.optim.SGD(model_lin_torch.parameters(), lr=0.01)\n",
    "\n",
    "for e in range(nb_epochs):\n",
    "    optimizer_lin_torch.zero_grad()\n",
    "    output_lin_torch = model_lin_torch(input)\n",
    "    loss_lin_torch = criterion_lin_torch(output_lin_torch, target)\n",
    "    print(\"e = {}, loss = {}\".format(e, round(loss_lin_torch.item(), 5)))\n",
    "    loss_lin_torch.backward()\n",
    "    optimizer_lin_torch.step()\n",
    "    \n",
    "del nn\n",
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.5055, -0.5256, -0.5978],\n",
      "        [ 0.3847, -0.6245, -0.4432],\n",
      "        [-0.5773, -0.9464,  0.2816],\n",
      "        [ 0.9112, -0.0370, -0.0581],\n",
      "        [ 0.6176, -0.6392,  0.8895],\n",
      "        [-0.9584, -0.9219, -0.6092]])\n",
      "Parameter containing:\n",
      "tensor([-0.1793, -0.0232, -0.4167, -0.0853,  0.2761, -0.3865])\n",
      "Parameter containing:\n",
      "tensor([[ 0.0910,  0.5517, -0.0885, -0.4841, -0.0721,  0.1615]])\n",
      "Parameter containing:\n",
      "tensor([0.6264])\n"
     ]
    }
   ],
   "source": [
    "model_seq = Sequential(\n",
    "    Linear('fc1', 3, 6), \n",
    "    ReLU('relu'),\n",
    "    Linear('fc2', 6, 1), \n",
    "    Tanh())\n",
    "print_parameters_as_torch(model_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.5055, -0.5256, -0.5978],\n",
      "        [ 0.3847, -0.6245, -0.4432],\n",
      "        [-0.5773, -0.9464,  0.2816],\n",
      "        [ 0.9112, -0.0370, -0.0581],\n",
      "        [ 0.6176, -0.6392,  0.8895],\n",
      "        [-0.9584, -0.9219, -0.6092]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.1793, -0.0232, -0.4167, -0.0853,  0.2761, -0.3865],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0910,  0.5517, -0.0885, -0.4841, -0.0721,  0.1615]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.6264], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "import Module, modules, helpers\n",
    "reload(Module)\n",
    "reload(modules)\n",
    "reload(helpers)\n",
    "from modules import *\n",
    "from helpers import *\n",
    "\n",
    "from torch import nn\n",
    "model_seq_torch = nn.Sequential(\n",
    "    nn.Linear(3, 6),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(6, 1),\n",
    "    nn.Tanh())\n",
    "set_initial_parameters(model_seq, model_seq_torch)\n",
    "for param in model_seq_torch.parameters():\n",
    "    print(param)\n",
    "del nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7, 1])\n",
      "e = 0, loss = 6.12547, grad_output = tensor([[-0.6504, -0.2288, -0.1767, -1.1079, -0.3291, -0.3468, -1.2401]])\n",
      "torch.Size([7, 1])\n",
      "e = 1, loss = 4.7175, grad_output = tensor([[-0.4679, -0.1149, -0.1506, -1.0112, -0.1725, -0.1816, -1.1643]])\n",
      "torch.Size([7, 1])\n",
      "e = 2, loss = 2.7998, grad_output = tensor([[-0.3443, -0.0590, -0.1388, -0.7835, -0.1107, -0.1119, -0.9055]])\n",
      "torch.Size([7, 1])\n",
      "e = 3, loss = 1.87299, grad_output = tensor([[-0.3079, -0.0286, -0.1267, -0.6358, -0.0807, -0.0821, -0.7356]])\n",
      "torch.Size([7, 1])\n",
      "e = 4, loss = 1.75919, grad_output = tensor([[-0.3021, -0.0220, -0.1221, -0.6134, -0.0747, -0.0763, -0.7148]])\n",
      "\n",
      "e = 0, loss = 6.12547\n",
      "grad_output =  tensor([[-0.6504, -0.2288, -0.1767, -1.1079, -0.3291, -0.3468, -1.2401]])\n",
      "e = 1, loss = 4.7175\n",
      "grad_output =  tensor([[-0.4679, -0.1149, -0.1506, -1.0112, -0.1725, -0.1816, -1.1643]])\n",
      "e = 2, loss = 2.7998\n",
      "grad_output =  tensor([[-0.3443, -0.0590, -0.1388, -0.7835, -0.1107, -0.1119, -0.9055]])\n",
      "e = 3, loss = 1.87299\n",
      "grad_output =  tensor([[-0.3079, -0.0286, -0.1267, -0.6358, -0.0807, -0.0821, -0.7356]])\n",
      "e = 4, loss = 1.75919\n",
      "grad_output =  tensor([[-0.3021, -0.0220, -0.1221, -0.6134, -0.0747, -0.0763, -0.7148]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x7f9a2c26cf60>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion_seq = MSELoss()\n",
    "optimizer_seq = SGD(model_seq, lr=0.01)\n",
    "\n",
    "for e in range(nb_epochs):\n",
    "    optimizer_seq.zero_grad()\n",
    "    output_seq = model_seq(input)\n",
    "    loss_seq = criterion_seq(output_seq, target)\n",
    "    grad_output_seq = criterion_seq.backward()\n",
    "    print(grad_output_seq.shape)\n",
    "    print(\"e = {}, loss = {}, grad_output = {}\".format(e, round(loss_seq.item(), 5), grad_output_seq.t()))\n",
    "    model_seq.backward(grad_output_seq)\n",
    "    optimizer_seq.step(loss_seq)\n",
    "\n",
    "print()\n",
    "from torch import nn\n",
    "torch.set_grad_enabled(True)\n",
    "    \n",
    "model_seq_torch.register_backward_hook(hook)     \n",
    "criterion_seq_torch = nn.MSELoss()\n",
    "optimizer_seq_torch = torch.optim.SGD(model_seq_torch.parameters(), lr=0.01)\n",
    "\n",
    "for e in range(nb_epochs):\n",
    "    optimizer_seq_torch.zero_grad()\n",
    "    output_seq_torch = model_seq_torch(input)\n",
    "    loss_seq_torch = criterion_seq_torch(output_seq_torch, target)\n",
    "    print(\"e = {}, loss = {}\".format(e, round(loss_seq_torch.item(), 5)))\n",
    "    loss_seq_torch.backward()\n",
    "    optimizer_seq_torch.step()\n",
    "    \n",
    "del nn\n",
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests on mnist-pairs data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_hidden1 = 100\n",
    "nb_hidden2 = 40\n",
    "train_input = train_input.view(len(train_input), -1)\n",
    "train_target = train_target.type(torch.FloatTensor)\n",
    "input_size = train_input.shape[1] # 392\n",
    "nb_epochs = 100\n",
    "\n",
    "model_mnist = Sequential(\n",
    "    Linear('fc1', input_size, nb_hidden1), ReLU(),\n",
    "    Linear('fc2', nb_hidden1, nb_hidden2), Tanh(),\n",
    "    Linear('fc3', nb_hidden2, 1))\n",
    "\n",
    "from torch import nn\n",
    "model_mnist_torch = nn.Sequential(\n",
    "    nn.Linear(input_size, nb_hidden1), nn.ReLU(),\n",
    "    nn.Linear(nb_hidden1, nb_hidden2), nn.Tanh(),\n",
    "    nn.Linear(nb_hidden2, 1))\n",
    "set_initial_parameters(model_mnist, model_mnist_torch)\n",
    "del nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x7f9a2c272358>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion_mnist = MSELoss()\n",
    "optimizer_mnist = SGD(model_mnist, lr=0.01)\n",
    "loss_history_mnist = []\n",
    "\n",
    "for e in range(nb_epochs):\n",
    "    optimizer_mnist.zero_grad()\n",
    "    output_mnist = model_mnist(train_input) # torch.Size([1000, 1])\n",
    "    loss_mnist = criterion_mnist(output_mnist.flatten(), train_target)\n",
    "    loss_history_mnist.append(loss_mnist)\n",
    "    grad_output_mnist = criterion_mnist.backward().view(-1,1)\n",
    "    #print(\"e = {}, loss = {}\".format(e, round(loss_mnist.item(), 5)))\n",
    "    model_mnist.backward(grad_output_mnist)\n",
    "    optimizer_mnist.step(loss_mnist)\n",
    "\n",
    "print()\n",
    "from torch import nn\n",
    "torch.set_grad_enabled(True)\n",
    "        \n",
    "criterion_mnist_torch = nn.MSELoss()\n",
    "optimizer_mnist_torch = torch.optim.SGD(model_mnist_torch.parameters(), lr=0.01)\n",
    "loss_history_mnist_torch = []\n",
    "\n",
    "for e in range(nb_epochs):\n",
    "    optimizer_mnist_torch.zero_grad()\n",
    "    output_mnist_torch = model_mnist_torch(train_input)\n",
    "    loss_mnist_torch = criterion_mnist_torch(output_mnist_torch, train_target)\n",
    "    loss_history_mnist_torch.append(loss_mnist_torch)\n",
    "    #print(\"e = {}, loss = {}\".format(e, round(loss_mnist_torch.item(), 5)))\n",
    "    loss_mnist_torch.backward()\n",
    "    optimizer_mnist_torch.step()\n",
    "    \n",
    "del nn\n",
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(loss_history_mnist, label='Custom DL framework')\n",
    "plt.plot(loss_history_mnist_torch, label='PyTorch')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
