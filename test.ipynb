{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import dlc_practical_prologue as prologue\n",
    "from importlib import reload\n",
    "reload(prologue)\n",
    "from dlc_practical_prologue import *\n",
    "import Module, modules, optimizers, helpers\n",
    "reload(Module)\n",
    "reload(modules)\n",
    "reload(helpers)\n",
    "from modules import *\n",
    "from helpers import *\n",
    "from optimizers import *\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "train_input, train_target, train_classes, test_input, test_target, test_classes = \\\n",
    "       load_random_datasets()\n",
    "\n",
    "input = torch.Tensor([[2., 4., 6.], [1., 4., 6.], [0.5, 3., 2.], [4.3, 4., 5.],\n",
    "                      [1.3, 4.1, 6.4], [1.4, 4.1, 6.5], [5, 4., 6.]])\n",
    "target = torch.Tensor([[2], [1], [1.1], [3], [1.2], [1.21], [3.4]])\n",
    "nb_epochs = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standalone Linear Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.4593, -0.5606, -0.0493]])\n",
      "Parameter containing:\n",
      "tensor([0.8749])\n"
     ]
    }
   ],
   "source": [
    "model_lin = Linear('fc1', 3, 1)\n",
    "print_parameters_as_torch(model_lin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.4593, -0.5606, -0.0493]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.8749], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "torch.set_grad_enabled(True)\n",
    "model_lin_torch = nn.Linear(3, 1)\n",
    "set_initial_parameters(model_lin, model_lin_torch)\n",
    "for param in model_lin_torch.parameters():\n",
    "    print(param)\n",
    "del nn\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "def hook(module, grad_input, grad_output):\n",
    "    for grad in grad_output:\n",
    "        print(\"grad_output = \", grad_output[0].t())\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e = 0, loss = 22.67716, grad_output = tensor([[-1.3090, -0.8920, -0.6385, -1.8825, -1.0102, -1.0276, -2.1027]])\n",
      "e = 1, loss = 1.74668, grad_output = tensor([[ 0.1117,  0.4567,  0.0066, -0.4381,  0.4269,  0.4309, -0.4661]])\n",
      "e = 2, loss = 1.55039, grad_output = tensor([[ 0.0306,  0.3688, -0.0330, -0.4922,  0.3359,  0.3394, -0.5268]])\n",
      "e = 3, loss = 1.42432, grad_output = tensor([[ 0.0297,  0.3581, -0.0359, -0.4676,  0.3268,  0.3310, -0.4984]])\n",
      "e = 4, loss = 1.30902, grad_output = tensor([[ 0.0247,  0.3439, -0.0404, -0.4481,  0.3140,  0.3188, -0.4758]])\n",
      "\n",
      "e = 0, loss = 22.67716\n",
      "grad_output =  tensor([[-1.3090, -0.8920, -0.6385, -1.8825, -1.0102, -1.0276, -2.1027]])\n",
      "e = 1, loss = 1.74668\n",
      "grad_output =  tensor([[ 0.1117,  0.4567,  0.0066, -0.4381,  0.4269,  0.4309, -0.4661]])\n",
      "e = 2, loss = 1.55039\n",
      "grad_output =  tensor([[ 0.0306,  0.3688, -0.0330, -0.4922,  0.3359,  0.3394, -0.5268]])\n",
      "e = 3, loss = 1.42432\n",
      "grad_output =  tensor([[ 0.0297,  0.3581, -0.0359, -0.4676,  0.3268,  0.3310, -0.4984]])\n",
      "e = 4, loss = 1.30902\n",
      "grad_output =  tensor([[ 0.0247,  0.3439, -0.0404, -0.4481,  0.3140,  0.3188, -0.4758]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x7f839cba9be0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion_lin = MSELoss()\n",
    "optimizer_lin = SGD(model_lin, lr=0.01)\n",
    "\n",
    "for e in range(nb_epochs):\n",
    "    optimizer_lin.zero_grad()\n",
    "    output_lin = model_lin(input)\n",
    "    loss_lin = criterion_lin(output_lin, target)\n",
    "    grad_output_lin = criterion_lin.backward()\n",
    "    print(\"e = {}, loss = {}, grad_output = {}\".format(e, round(loss_lin.item(), 5), grad_output_lin.t()))\n",
    "    model_lin.backward(grad_output_lin)\n",
    "    optimizer_lin.step(loss_lin)\n",
    " \n",
    "print()\n",
    "from torch import nn\n",
    "torch.set_grad_enabled(True)\n",
    "    \n",
    "model_lin_torch.register_backward_hook(hook)     \n",
    "criterion_lin_torch = nn.MSELoss()\n",
    "optimizer_lin_torch = torch.optim.SGD(model_lin_torch.parameters(), lr=0.01)\n",
    "\n",
    "for e in range(nb_epochs):\n",
    "    optimizer_lin_torch.zero_grad()\n",
    "    output_lin_torch = model_lin_torch(input)\n",
    "    loss_lin_torch = criterion_lin_torch(output_lin_torch, target)\n",
    "    print(\"e = {}, loss = {}\".format(e, round(loss_lin_torch.item(), 5)))\n",
    "    loss_lin_torch.backward()\n",
    "    optimizer_lin_torch.step()\n",
    "    \n",
    "del nn\n",
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.5055, -0.5256, -0.5978],\n",
      "        [ 0.3847, -0.6245, -0.4432],\n",
      "        [-0.5773, -0.9464,  0.2816],\n",
      "        [ 0.9112, -0.0370, -0.0581],\n",
      "        [ 0.6176, -0.6392,  0.8895],\n",
      "        [-0.9584, -0.9219, -0.6092]])\n",
      "Parameter containing:\n",
      "tensor([-0.1793, -0.0232, -0.4167, -0.0853,  0.2761, -0.3865])\n",
      "Parameter containing:\n",
      "tensor([[ 0.0910,  0.5517, -0.0885, -0.4841, -0.0721,  0.1615]])\n",
      "Parameter containing:\n",
      "tensor([0.6264])\n"
     ]
    }
   ],
   "source": [
    "model_seq = Sequential(\n",
    "    Linear('fc1', 3, 6), \n",
    "    ReLU('relu'),\n",
    "    Linear('fc2', 6, 1), \n",
    "    Tanh())\n",
    "print_parameters_as_torch(model_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.5055, -0.5256, -0.5978],\n",
      "        [ 0.3847, -0.6245, -0.4432],\n",
      "        [-0.5773, -0.9464,  0.2816],\n",
      "        [ 0.9112, -0.0370, -0.0581],\n",
      "        [ 0.6176, -0.6392,  0.8895],\n",
      "        [-0.9584, -0.9219, -0.6092]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.1793, -0.0232, -0.4167, -0.0853,  0.2761, -0.3865],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0910,  0.5517, -0.0885, -0.4841, -0.0721,  0.1615]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.6264], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "import Module, modules, helpers\n",
    "reload(Module)\n",
    "reload(modules)\n",
    "reload(helpers)\n",
    "from modules import *\n",
    "from helpers import *\n",
    "\n",
    "from torch import nn\n",
    "model_seq_torch = nn.Sequential(\n",
    "    nn.Linear(3, 6),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(6, 1),\n",
    "    nn.Tanh())\n",
    "set_initial_parameters(model_seq, model_seq_torch)\n",
    "for param in model_seq_torch.parameters():\n",
    "    print(param)\n",
    "del nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e = 0, loss = 6.12547, grad_output = tensor([[-0.6504, -0.2288, -0.1767, -1.1079, -0.3291, -0.3468, -1.2401]])\n",
      "e = 1, loss = 4.7175, grad_output = tensor([[-0.4679, -0.1149, -0.1506, -1.0112, -0.1725, -0.1816, -1.1643]])\n",
      "e = 2, loss = 2.7998, grad_output = tensor([[-0.3443, -0.0590, -0.1388, -0.7835, -0.1107, -0.1119, -0.9055]])\n",
      "e = 3, loss = 1.87299, grad_output = tensor([[-0.3079, -0.0286, -0.1267, -0.6358, -0.0807, -0.0821, -0.7356]])\n",
      "e = 4, loss = 1.75919, grad_output = tensor([[-0.3021, -0.0220, -0.1221, -0.6134, -0.0747, -0.0763, -0.7148]])\n",
      "\n",
      "e = 0, loss = 6.12547\n",
      "grad_output =  tensor([[-0.6504, -0.2288, -0.1767, -1.1079, -0.3291, -0.3468, -1.2401]])\n",
      "e = 1, loss = 4.7175\n",
      "grad_output =  tensor([[-0.4679, -0.1149, -0.1506, -1.0112, -0.1725, -0.1816, -1.1643]])\n",
      "e = 2, loss = 2.7998\n",
      "grad_output =  tensor([[-0.3443, -0.0590, -0.1388, -0.7835, -0.1107, -0.1119, -0.9055]])\n",
      "e = 3, loss = 1.87299\n",
      "grad_output =  tensor([[-0.3079, -0.0286, -0.1267, -0.6358, -0.0807, -0.0821, -0.7356]])\n",
      "e = 4, loss = 1.75919\n",
      "grad_output =  tensor([[-0.3021, -0.0220, -0.1221, -0.6134, -0.0747, -0.0763, -0.7148]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x7f83a2926320>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion_seq = MSELoss()\n",
    "optimizer_seq = SGD(model_seq, lr=0.01)\n",
    "\n",
    "for e in range(nb_epochs):\n",
    "    optimizer_seq.zero_grad()\n",
    "    output_seq = model_seq(input)\n",
    "    loss_seq = criterion_seq(output_seq, target)\n",
    "    grad_output_seq = criterion_seq.backward()\n",
    "    #print(grad_output_seq.shape)\n",
    "    print(\"e = {}, loss = {}, grad_output = {}\".format(e, round(loss_seq.item(), 5), grad_output_seq.t()))\n",
    "    model_seq.backward(grad_output_seq)\n",
    "    optimizer_seq.step(loss_seq)\n",
    "\n",
    "print()\n",
    "from torch import nn\n",
    "torch.set_grad_enabled(True)\n",
    "    \n",
    "model_seq_torch.register_backward_hook(hook)     \n",
    "criterion_seq_torch = nn.MSELoss()\n",
    "optimizer_seq_torch = torch.optim.SGD(model_seq_torch.parameters(), lr=0.01)\n",
    "\n",
    "for e in range(nb_epochs):\n",
    "    optimizer_seq_torch.zero_grad()\n",
    "    output_seq_torch = model_seq_torch(input)\n",
    "    loss_seq_torch = criterion_seq_torch(output_seq_torch, target)\n",
    "    print(\"e = {}, loss = {}\".format(e, round(loss_seq_torch.item(), 5)))\n",
    "    loss_seq_torch.backward()\n",
    "    optimizer_seq_torch.step()\n",
    "    \n",
    "del nn\n",
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential Module with multiple sigmoid and Binary-Cross-Entropy Loss\n",
    "Idea: check behavior of sigmoid and with multiple parameterless (same) functions without unique names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.0871, -0.2809, -0.6147],\n",
      "        [ 0.8904,  0.9812, -0.3240],\n",
      "        [-0.4314,  0.6022,  0.1325],\n",
      "        [ 0.4467, -0.3703,  0.1463],\n",
      "        [ 0.5268,  0.7447,  0.5614],\n",
      "        [ 0.9037,  0.5998,  0.1722]])\n",
      "Parameter containing:\n",
      "tensor([-0.0836, -0.8084,  0.2817, -0.0101,  0.4545,  0.9739])\n",
      "Parameter containing:\n",
      "tensor([[ 0.4564,  0.0860,  0.0347, -0.0512, -0.3506,  0.2918]])\n",
      "Parameter containing:\n",
      "tensor([-0.5381])\n"
     ]
    }
   ],
   "source": [
    "model_seq_sigmoid = Sequential(\n",
    "    Linear('fc1', 3, 6), \n",
    "    Sigmoid('sig1'),\n",
    "    Linear('fc2', 6, 1), \n",
    "    Sigmoid('sig2'))\n",
    "print_parameters_as_torch(model_seq_sigmoid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.0871, -0.2809, -0.6147],\n",
      "        [ 0.8904,  0.9812, -0.3240],\n",
      "        [-0.4314,  0.6022,  0.1325],\n",
      "        [ 0.4467, -0.3703,  0.1463],\n",
      "        [ 0.5268,  0.7447,  0.5614],\n",
      "        [ 0.9037,  0.5998,  0.1722]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0836, -0.8084,  0.2817, -0.0101,  0.4545,  0.9739],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.4564,  0.0860,  0.0347, -0.0512, -0.3506,  0.2918]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.5381], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "import Module, modules, helpers\n",
    "reload(Module)\n",
    "reload(modules)\n",
    "reload(helpers)\n",
    "from modules import *\n",
    "from helpers import *\n",
    "\n",
    "from torch import nn\n",
    "model_seq_sigmoid_torch = nn.Sequential(\n",
    "    nn.Linear(3, 6),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(6, 1),\n",
    "    nn.Sigmoid())\n",
    "set_initial_parameters(model_seq_sigmoid, model_seq_sigmoid_torch)\n",
    "for param in model_seq_sigmoid_torch.parameters():\n",
    "    print(param)\n",
    "del nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e = 0, loss = 2.99611, grad_output = tensor([[-0.4641, -0.1784, -0.2038, -0.7501, -0.2356, -0.2385, -0.8650]])\n",
      "grad_ouput.shape =  torch.Size([7, 1])\n",
      "e = 1, loss = 2.97189, grad_output = tensor([[-0.4618, -0.1761, -0.2016, -0.7477, -0.2333, -0.2361, -0.8626]])\n",
      "grad_ouput.shape =  torch.Size([7, 1])\n",
      "e = 2, loss = 2.94754, grad_output = tensor([[-0.4594, -0.1738, -0.1993, -0.7453, -0.2309, -0.2338, -0.8602]])\n",
      "grad_ouput.shape =  torch.Size([7, 1])\n",
      "e = 3, loss = 2.92308, grad_output = tensor([[-0.4570, -0.1714, -0.1970, -0.7429, -0.2285, -0.2314, -0.8577]])\n",
      "grad_ouput.shape =  torch.Size([7, 1])\n",
      "e = 4, loss = 2.89856, grad_output = tensor([[-0.4545, -0.1690, -0.1947, -0.7404, -0.2261, -0.2290, -0.8552]])\n",
      "grad_ouput.shape =  torch.Size([7, 1])\n",
      "e = 5, loss = 2.87399, grad_output = tensor([[-0.4521, -0.1667, -0.1924, -0.7379, -0.2237, -0.2266, -0.8527]])\n",
      "grad_ouput.shape =  torch.Size([7, 1])\n",
      "e = 6, loss = 2.84942, grad_output = tensor([[-0.4496, -0.1643, -0.1900, -0.7354, -0.2213, -0.2242, -0.8502]])\n",
      "grad_ouput.shape =  torch.Size([7, 1])\n",
      "e = 7, loss = 2.82487, grad_output = tensor([[-0.4472, -0.1618, -0.1877, -0.7329, -0.2189, -0.2217, -0.8477]])\n",
      "grad_ouput.shape =  torch.Size([7, 1])\n",
      "e = 8, loss = 2.80038, grad_output = tensor([[-0.4447, -0.1594, -0.1853, -0.7304, -0.2164, -0.2193, -0.8452]])\n",
      "grad_ouput.shape =  torch.Size([7, 1])\n",
      "e = 9, loss = 2.77598, grad_output = tensor([[-0.4422, -0.1570, -0.1830, -0.7279, -0.2140, -0.2168, -0.8426]])\n",
      "grad_ouput.shape =  torch.Size([7, 1])\n",
      "\n",
      "e = 0, loss = 2.99611\n",
      "grad_output =  tensor([[-0.4641, -0.1784, -0.2038, -0.7501, -0.2356, -0.2385, -0.8650]])\n",
      "e = 1, loss = 2.97189\n",
      "grad_output =  tensor([[-0.4618, -0.1761, -0.2016, -0.7477, -0.2333, -0.2361, -0.8626]])\n",
      "e = 2, loss = 2.94754\n",
      "grad_output =  tensor([[-0.4594, -0.1738, -0.1993, -0.7453, -0.2309, -0.2338, -0.8602]])\n",
      "e = 3, loss = 2.92308\n",
      "grad_output =  tensor([[-0.4570, -0.1714, -0.1970, -0.7429, -0.2285, -0.2314, -0.8577]])\n",
      "e = 4, loss = 2.89856\n",
      "grad_output =  tensor([[-0.4545, -0.1690, -0.1947, -0.7404, -0.2261, -0.2290, -0.8552]])\n",
      "e = 5, loss = 2.87399\n",
      "grad_output =  tensor([[-0.4521, -0.1667, -0.1924, -0.7379, -0.2237, -0.2266, -0.8527]])\n",
      "e = 6, loss = 2.84942\n",
      "grad_output =  tensor([[-0.4496, -0.1643, -0.1900, -0.7354, -0.2213, -0.2242, -0.8502]])\n",
      "e = 7, loss = 2.82487\n",
      "grad_output =  tensor([[-0.4472, -0.1618, -0.1877, -0.7329, -0.2189, -0.2217, -0.8477]])\n",
      "e = 8, loss = 2.80038\n",
      "grad_output =  tensor([[-0.4447, -0.1594, -0.1853, -0.7304, -0.2164, -0.2193, -0.8452]])\n",
      "e = 9, loss = 2.77598\n",
      "grad_output =  tensor([[-0.4422, -0.1570, -0.1830, -0.7279, -0.2140, -0.2168, -0.8426]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x7f83a2944fd0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion_seq_sigmoid = MSELoss()\n",
    "optimizer_seq_sigmoid = SGD(model_seq_sigmoid, lr=0.01)\n",
    "\n",
    "nb_epochs = 10\n",
    "for e in range(nb_epochs):\n",
    "    optimizer_seq_sigmoid.zero_grad()\n",
    "    output_seq_sigmoid = model_seq_sigmoid(input)\n",
    "    loss_seq_sigmoid = criterion_seq_sigmoid(output_seq_sigmoid, target)\n",
    "    grad_output_seq_sigmoid = criterion_seq_sigmoid.backward()\n",
    "    print(\"e = {}, loss = {}, grad_output = {}\".format(e, round(loss_seq_sigmoid.item(), 5), grad_output_seq_sigmoid.t()))\n",
    "    print(\"grad_ouput.shape = \", grad_output_seq_sigmoid.shape)\n",
    "    model_seq_sigmoid.backward(grad_output_seq_sigmoid)\n",
    "    optimizer_seq_sigmoid.step(loss_seq_sigmoid)\n",
    "\n",
    "print()\n",
    "from torch import nn\n",
    "torch.set_grad_enabled(True)\n",
    "    \n",
    "model_seq_sigmoid_torch.register_backward_hook(hook)     \n",
    "criterion_seq_sigmoid_torch = nn.MSELoss()\n",
    "optimizer_seq_sigmoid_torch = torch.optim.SGD(model_seq_sigmoid_torch.parameters(), lr=0.01)\n",
    "\n",
    "for e in range(nb_epochs):\n",
    "    optimizer_seq_sigmoid_torch.zero_grad()\n",
    "    output_seq_sigmoid_torch = model_seq_sigmoid_torch(input)\n",
    "    loss_seq_sigmoid_torch = criterion_seq_sigmoid_torch(output_seq_sigmoid_torch, target)\n",
    "    print(\"e = {}, loss = {}\".format(e, round(loss_seq_sigmoid_torch.item(), 5)))\n",
    "    loss_seq_sigmoid_torch.backward()\n",
    "    optimizer_seq_sigmoid_torch.step()\n",
    "    \n",
    "del nn\n",
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e = 0, loss = 0.73909, grad_output = tensor([[ 2.5906, -1.6433,  2.3305,  2.7748,  2.5608, -1.6392, -1.5278]])\n",
      "e = 1, loss = 0.73136, grad_output = tensor([[ 2.5178, -1.6716,  2.2855,  2.6837,  2.4928, -1.6686, -1.5576]])\n",
      "e = 2, loss = 0.72465, grad_output = tensor([[ 2.4533, -1.6991,  2.2450,  2.6036,  2.4324, -1.6971, -1.5867]])\n",
      "e = 3, loss = 0.7188, grad_output = tensor([[ 2.3959, -1.7257,  2.2082,  2.5329,  2.3784, -1.7247, -1.6148]])\n",
      "e = 4, loss = 0.71371, grad_output = tensor([[ 2.3446, -1.7513,  2.1749,  2.4702,  2.3300, -1.7513, -1.6420]])\n",
      "e = 5, loss = 0.70925, grad_output = tensor([[ 2.2986, -1.7761,  2.1446,  2.4144,  2.2864, -1.7770, -1.6683]])\n",
      "e = 6, loss = 0.70536, grad_output = tensor([[ 2.2571, -1.7999,  2.1169,  2.3644,  2.2471, -1.8017, -1.6936]])\n",
      "e = 7, loss = 0.70195, grad_output = tensor([[ 2.2197, -1.8227,  2.0916,  2.3196,  2.2115, -1.8255, -1.7179]])\n",
      "e = 8, loss = 0.69896, grad_output = tensor([[ 2.1859, -1.8447,  2.0684,  2.2793,  2.1792, -1.8483, -1.7412]])\n",
      "e = 9, loss = 0.69634, grad_output = tensor([[ 2.1552, -1.8657,  2.0471,  2.2429,  2.1499, -1.8701, -1.7635]])\n",
      "\n",
      "e = 0, loss = 0.69099\n",
      "grad_output =  tensor([[ 0.2711, -0.2995,  0.2830,  0.2727,  0.2719, -0.3013, -0.2983]])\n",
      "e = 1, loss = 0.69093\n",
      "grad_output =  tensor([[ 0.2710, -0.2997,  0.2828,  0.2726,  0.2718, -0.3015, -0.2984]])\n",
      "e = 2, loss = 0.69088\n",
      "grad_output =  tensor([[ 0.2708, -0.2998,  0.2827,  0.2725,  0.2717, -0.3016, -0.2985]])\n",
      "e = 3, loss = 0.69083\n",
      "grad_output =  tensor([[ 0.2707, -0.3000,  0.2825,  0.2724,  0.2715, -0.3018, -0.2987]])\n",
      "e = 4, loss = 0.69077\n",
      "grad_output =  tensor([[ 0.2706, -0.3001,  0.2824,  0.2722,  0.2714, -0.3019, -0.2988]])\n",
      "e = 5, loss = 0.69072\n",
      "grad_output =  tensor([[ 0.2705, -0.3003,  0.2822,  0.2721,  0.2713, -0.3021, -0.2989]])\n",
      "e = 6, loss = 0.69067\n",
      "grad_output =  tensor([[ 0.2704, -0.3004,  0.2821,  0.2720,  0.2712, -0.3022, -0.2991]])\n",
      "e = 7, loss = 0.69061\n",
      "grad_output =  tensor([[ 0.2702, -0.3006,  0.2820,  0.2719,  0.2710, -0.3024, -0.2992]])\n",
      "e = 8, loss = 0.69056\n",
      "grad_output =  tensor([[ 0.2701, -0.3007,  0.2818,  0.2718,  0.2709, -0.3025, -0.2993]])\n",
      "e = 9, loss = 0.69051\n",
      "grad_output =  tensor([[ 0.2700, -0.3009,  0.2817,  0.2717,  0.2708, -0.3027, -0.2994]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x7f83a2939a90>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_bce = torch.Tensor([0, 1, 0, 0, 0, 1, 1])\n",
    "\n",
    "model_seq_bce = Sequential(\n",
    "    Linear('fc1', 3, 6), \n",
    "    Sigmoid('sig1'),\n",
    "    Linear('fc2', 6, 1), \n",
    "    Sigmoid('sig2'))\n",
    "\n",
    "from torch import nn\n",
    "model_seq_bce_torch = nn.Sequential(\n",
    "    nn.Linear(3, 6),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(6, 1),\n",
    "    nn.Sigmoid())\n",
    "set_initial_parameters(model_seq_sigmoid, model_seq_sigmoid_torch)\n",
    "del nn\n",
    "\n",
    "criterion_seq_bce = BCELoss()\n",
    "optimizer_seq_bce = SGD(model_seq_bce, lr=0.01)\n",
    "\n",
    "nb_epochs = 10\n",
    "for e in range(nb_epochs):\n",
    "    optimizer_seq_bce.zero_grad()\n",
    "    output_seq_bce = model_seq_bce(input).view(-1)\n",
    "    loss_seq_bce = criterion_seq_bce(input=output_seq_bce, target=target_bce)\n",
    "    grad_output_seq_bce = criterion_seq_bce.backward().view((-1, 1))\n",
    "    print(\"e = {}, loss = {}, grad_output = {}\".format(e, round(loss_seq_bce.item(), 5), grad_output_seq_bce.t()))\n",
    "    model_seq_bce.backward(grad_output_seq_bce)\n",
    "    optimizer_seq_bce.step(loss_seq_bce)\n",
    "\n",
    "print()\n",
    "from torch import nn\n",
    "torch.set_grad_enabled(True)\n",
    "\n",
    "model_seq_bce_torch.register_backward_hook(hook)\n",
    "criterion_seq_bce_torch = nn.BCELoss()\n",
    "optimizer_seq_bce_torch = torch.optim.SGD(model_seq_bce_torch.parameters(), lr=0.01)\n",
    "\n",
    "for e in range(nb_epochs):\n",
    "    optimizer_seq_bce_torch.zero_grad()\n",
    "    output_seq_bce_torch = model_seq_bce_torch(input)\n",
    "    loss_seq_bce_torch = criterion_seq_bce_torch(output_seq_bce_torch.view(-1), target_bce)\n",
    "    print(\"e = {}, loss = {}\".format(e, round(loss_seq_bce_torch.item(), 5)))\n",
    "    loss_seq_bce_torch.backward()\n",
    "    optimizer_seq_bce_torch.step()\n",
    "    \n",
    "del nn\n",
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.9623, -0.3760, -0.2283]])\n",
      "\n",
      "output =  tensor([[0.0082, 0.0211, 0.1125, 0.0011, 0.0140, 0.0125, 0.0005]])\n",
      "grad_output =  tensor([[  1.0082, -47.3441,  -8.8916,   1.0011, -71.3648, -80.2612,   1.0005]])\n",
      "p.grad =  tensor([[ -4.0635, -14.6305, -20.3202]])\n",
      "\n",
      "\n",
      "grad_output =  tensor([[  0.1440,  -6.7634,  -1.2702,   0.1430, -10.1950, -11.4659,   0.1429]])\n",
      "p.grad =  tensor([[-0.5805, -2.0901, -2.9029]])\n"
     ]
    }
   ],
   "source": [
    "import Module, modules, helpers\n",
    "reload(Module)\n",
    "reload(modules)\n",
    "reload(helpers)\n",
    "from modules import *\n",
    "from helpers import *\n",
    "\n",
    "input = torch.Tensor([[2., 4., 6.], [1., 4., 6.], [0.5, 3., 2.], [4.3, 4., 5.],\n",
    "                      [1.3, 4.1, 6.4], [1.4, 4.1, 6.5], [5, 4., 6.]])\n",
    "target = torch.Tensor([[0], [1], [1], [0], [1], [1], [0]])\n",
    "model_lin = Sequential(\n",
    "    Linear('fc1', 3, 1, bias=False),\n",
    "    Sigmoid())\n",
    "\n",
    "print_parameters_as_torch(model_lin)\n",
    "print()\n",
    "criterion = BCELoss()\n",
    "output = model_lin(input)\n",
    "print(\"output = \", output.t())\n",
    "loss = criterion(output.view(-1), target.view(-1))\n",
    "#print(\"loss = \", loss)\n",
    "\n",
    "grad_output = criterion.backward().view((-1, 1))\n",
    "print(\"grad_output = \", grad_output.t())\n",
    "grad_input = model_lin.backward(grad_output)\n",
    "#print(\"grad_input (grad of loss wrt to model output) = \", grad_input.t())\n",
    "for param_dict in model_lin.param():\n",
    "    param_dict = next(param_dict)\n",
    "    for p in param_dict.values():\n",
    "        print(\"p.grad = \", p.grad.t())\n",
    "\n",
    "print()\n",
    "from torch import nn\n",
    "torch.set_grad_enabled(True)\n",
    "\n",
    "criterion_torch = nn.BCELoss()\n",
    "model_torch = nn.Sequential(nn.Linear(3, 1, bias=False), nn.Sigmoid())\n",
    "model_torch.register_backward_hook(hook)\n",
    "set_initial_parameters(model_lin, model_torch)\n",
    "#for p in model_torch.parameters():\n",
    "    #print(p)\n",
    "print()   \n",
    "output = model_torch(input)\n",
    "#print(\"output = \", output.t().data)\n",
    "loss = criterion(output.view(-1), target.view(-1))\n",
    "#print(\"loss = \", loss.item())\n",
    "loss.backward()\n",
    "for p in model_torch.parameters():\n",
    "    print(\"p.grad = \", p.grad)\n",
    "\n",
    "\n",
    "                 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests on mnist-pairs data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_tensor_type(torch.FloatTensor)\n",
    "#  float is a single precision (32 bit) floating point data type, double is a double precision (64 bit) floating point\n",
    "nb_hidden1 = 20\n",
    "nb_hidden2 = 10\n",
    "train_input = train_input.view(len(train_input), -1)\n",
    "train_target = train_target.type(torch.FloatTensor)\n",
    "test_input = test_input.view(len(train_input), -1)\n",
    "test_target = test_target.type(torch.FloatTensor)\n",
    "input_size = train_input.shape[1] # 392\n",
    "nb_epochs = 300\n",
    "\n",
    "model_mnist = Sequential(\n",
    "    Linear('fc1', input_size, nb_hidden1), ReLU(),\n",
    "    Linear('fc2', nb_hidden1, nb_hidden2), Tanh(),\n",
    "    Linear('fc3', nb_hidden2, 1))\n",
    "\n",
    "from torch import nn\n",
    "model_mnist_torch = nn.Sequential(\n",
    "    nn.Linear(input_size, nb_hidden1), nn.ReLU(),\n",
    "    nn.Linear(nb_hidden1, nb_hidden2), nn.Tanh(),\n",
    "    nn.Linear(nb_hidden2, 1))\n",
    "set_initial_parameters(model_mnist, model_mnist_torch)\n",
    "del nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_input, test_target):\n",
    "    test_output = model(test_input)\n",
    "    output_to_prediction = torch.ge(torch.sigmoid(test_output), 0.5).flatten()\n",
    "    nb_correct = torch.sum(output_to_prediction == test_target.type(torch.ByteTensor)).item()\n",
    "    acc_pairs = nb_correct / len(test_input)\n",
    "    return acc_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e = 0, test accuracy = 0.508\n",
      "e = 40, test accuracy = 0.514\n",
      "e = 80, test accuracy = 0.529\n",
      "e = 120, test accuracy = 0.548\n",
      "e = 160, test accuracy = 0.553\n",
      "e = 200, test accuracy = 0.516\n",
      "e = 240, test accuracy = 0.513\n",
      "e = 280, test accuracy = 0.524\n",
      "\n",
      "e = 0, test accuracy = 0.508\n",
      "e = 40, test accuracy = 0.526\n",
      "e = 80, test accuracy = 0.526\n",
      "e = 120, test accuracy = 0.526\n",
      "e = 160, test accuracy = 0.526\n",
      "e = 200, test accuracy = 0.526\n",
      "e = 240, test accuracy = 0.526\n",
      "e = 280, test accuracy = 0.526\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x7f83a28e9eb8>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion_mnist = MSELoss()\n",
    "optimizer_mnist = SGD(model_mnist, lr=0.01)\n",
    "loss_history_mnist = []\n",
    "test_acc_history_mnist = []\n",
    "\n",
    "for e in range(nb_epochs):\n",
    "    optimizer_mnist.zero_grad()\n",
    "    output_mnist = model_mnist(train_input) # torch.Size([1000, 1])\n",
    "    loss_mnist = criterion_mnist(output_mnist.flatten(), train_target)\n",
    "    loss_history_mnist.append(loss_mnist)\n",
    "    grad_output_mnist = criterion_mnist.backward().view(-1,1)\n",
    "    test_acc_mnist = test_model(model_mnist, test_input, test_target)\n",
    "    test_acc_history_mnist.append(test_acc_mnist)\n",
    "    if e % 40 == 0: print(\"e = {}, test accuracy = {}\".format(e, test_acc_mnist))\n",
    "    model_mnist.backward(grad_output_mnist)\n",
    "    optimizer_mnist.step(loss_mnist)\n",
    "\n",
    "print()\n",
    "from torch import nn\n",
    "torch.set_grad_enabled(True)\n",
    "        \n",
    "criterion_mnist_torch = nn.MSELoss()\n",
    "optimizer_mnist_torch = torch.optim.SGD(model_mnist_torch.parameters(), lr=0.01)\n",
    "loss_history_mnist_torch = []\n",
    "test_acc_history_mnist_torch = []\n",
    "\n",
    "for e in range(nb_epochs):\n",
    "    optimizer_mnist_torch.zero_grad()\n",
    "    output_mnist_torch = model_mnist_torch(train_input)\n",
    "    loss_mnist_torch = criterion_mnist_torch(output_mnist_torch, train_target)\n",
    "    loss_history_mnist_torch.append(loss_mnist_torch)\n",
    "    test_acc_mnist_torch = test_model(model_mnist_torch, test_input, test_target)\n",
    "    test_acc_history_mnist_torch.append(test_acc_mnist_torch)\n",
    "    if e % 40 == 0: print(\"e = {}, test accuracy = {}\".format(e, test_acc_mnist_torch))\n",
    "    loss_mnist_torch.backward()\n",
    "    optimizer_mnist_torch.step()\n",
    "    \n",
    "del nn\n",
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(loss_history_mnist, label='Custom DL framework')\n",
    "plt.plot(loss_history_mnist_torch, label='PyTorch')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(test_acc_history_mnist, label='Custom DL framework')\n",
    "plt.plot(test_acc_history_mnist_torch, label='PyTorch')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
