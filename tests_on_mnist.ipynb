{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e = 0, test accuracy = 0.435, loss = 0.5342389345169067\n",
      "e = 40, test accuracy = 0.44, loss = 0.376302570104599\n",
      "e = 80, test accuracy = 0.453, loss = 0.41157200932502747\n",
      "e = 120, test accuracy = 0.472, loss = 0.5179829597473145\n",
      "e = 160, test accuracy = 0.503, loss = 0.8302551507949829\n",
      "e = 200, test accuracy = 0.537, loss = 4.003942966461182\n",
      "e = 240, test accuracy = 0.534, loss = 12.101386070251465\n",
      "e = 280, test accuracy = 0.517, loss = 16.579118728637695\n",
      "\n",
      "e = 0, test accuracy = 0.435, loss = 0.5342389345169067\n",
      "e = 40, test accuracy = 0.683, loss = 0.1847561001777649\n",
      "e = 80, test accuracy = 0.725, loss = 0.1547391265630722\n",
      "e = 120, test accuracy = 0.739, loss = 0.1388862580060959\n",
      "e = 160, test accuracy = 0.742, loss = 0.12781952321529388\n",
      "e = 200, test accuracy = 0.748, loss = 0.11909683793783188\n",
      "e = 240, test accuracy = 0.757, loss = 0.11175363510847092\n",
      "e = 280, test accuracy = 0.756, loss = 0.10531888902187347\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x7f0e766b6470>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import dlc_practical_prologue as prologue\n",
    "from importlib import reload\n",
    "reload(prologue)\n",
    "from dlc_practical_prologue import *\n",
    "import Module, modules, optimizers, helpers\n",
    "reload(Module)\n",
    "reload(modules)\n",
    "reload(helpers)\n",
    "from modules import *\n",
    "from helpers import *\n",
    "from optimizers import *\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "#torch.set_default_tensor_type(torch.DoubleTensor)\n",
    "\n",
    "def test_model(model, test_input, test_target):\n",
    "    test_output = model(test_input)\n",
    "    output_to_prediction = torch.ge(test_output, 0.5).flatten()\n",
    "    nb_correct = torch.sum(output_to_prediction == test_target.type(torch.ByteTensor)).item()\n",
    "    acc_pairs = nb_correct / len(test_input)\n",
    "    return acc_pairs\n",
    "\n",
    "train_input, train_target, train_classes, test_input, test_target, test_classes = \\\n",
    "       load_random_datasets()\n",
    "\n",
    "nb_hidden1 = 100\n",
    "nb_hidden2 = 40\n",
    "\n",
    "train_input = train_input.view(len(train_input), -1)\n",
    "train_target = train_target.type(torch.FloatTensor)\n",
    "test_input = test_input.view(len(train_input), -1)\n",
    "test_target = test_target.type(torch.FloatTensor)\n",
    "\n",
    "#train_input = train_input.view(len(train_input), -1).type(torch.DoubleTensor)\n",
    "#train_target = train_target.type(torch.DoubleTensor)\n",
    "#test_input = test_input.view(len(train_input), -1).type(torch.DoubleTensor)\n",
    "#test_target = test_target.type(torch.DoubleTensor)\n",
    "\n",
    "input_size = train_input.shape[1] # 392\n",
    "nb_epochs = 300\n",
    "\n",
    "model_mnist = Sequential(\n",
    "    Linear('fc1', input_size, nb_hidden1), ReLU(),\n",
    "    Linear('fc2', nb_hidden1, nb_hidden2), Tanh(),\n",
    "    Linear('fc3', nb_hidden2, 1))\n",
    "\n",
    "from torch import nn\n",
    "model_mnist_torch = nn.Sequential(\n",
    "    nn.Linear(input_size, nb_hidden1), nn.ReLU(),\n",
    "    nn.Linear(nb_hidden1, nb_hidden2), nn.Tanh(),\n",
    "    nn.Linear(nb_hidden2, 1))\n",
    "set_initial_parameters(model_mnist, model_mnist_torch)\n",
    "del nn\n",
    "\n",
    "\n",
    "lr = 0.01\n",
    "criterion_mnist = MSELoss()\n",
    "optimizer_mnist = SGD(model_mnist, lr=lr)\n",
    "loss_history_mnist = []\n",
    "test_acc_history_mnist = []\n",
    "nb_epochs = 300\n",
    "for e in range(nb_epochs):\n",
    "    optimizer_mnist.zero_grad()\n",
    "    \n",
    "    output_mnist = model_mnist(train_input) # torch.Size([1000, 1])\n",
    "    \n",
    "    loss_mnist = criterion_mnist(output_mnist.flatten(), train_target)\n",
    "    loss_history_mnist.append(loss_mnist)\n",
    "    \n",
    "    grad_output_mnist = criterion_mnist.backward().view(-1,1)\n",
    "    test_acc_mnist = test_model(model_mnist, test_input, test_target)\n",
    "    test_acc_history_mnist.append(test_acc_mnist)\n",
    "    if e % 40 == 0: print(\"e = {}, test accuracy = {}, loss = {}\".format(e, test_acc_mnist, loss_mnist))\n",
    "    #print(\"e = {}, test accuracy = {}, loss = {}\".format(e, test_acc_mnist, loss_mnist))\n",
    "    model_mnist.backward(grad_output_mnist)\n",
    "    optimizer_mnist.step(loss_mnist)\n",
    "\n",
    "print()\n",
    "from torch import nn\n",
    "torch.set_grad_enabled(True)\n",
    "\n",
    "criterion_mnist_torch = nn.MSELoss()\n",
    "optimizer_mnist_torch = torch.optim.SGD(model_mnist_torch.parameters(), lr=lr)\n",
    "loss_history_mnist_torch = []\n",
    "test_acc_history_mnist_torch = []\n",
    "\n",
    "for e in range(nb_epochs):\n",
    "    optimizer_mnist_torch.zero_grad()\n",
    "    output_mnist_torch = model_mnist_torch(train_input)\n",
    "    #print(\"output = \", output_mnist_torch[:5])\n",
    "    #print()\n",
    "    loss_mnist_torch = criterion_mnist_torch(output_mnist_torch.flatten(), train_target)\n",
    "    loss_history_mnist_torch.append(loss_mnist_torch)\n",
    "    test_acc_mnist_torch = test_model(model_mnist_torch, test_input, test_target)\n",
    "    test_acc_history_mnist_torch.append(test_acc_mnist_torch)\n",
    "    if e % 40 == 0: print(\"e = {}, test accuracy = {}, loss = {}\".format(e, test_acc_mnist_torch, loss_mnist_torch))\n",
    "    #print(\"e = {}, test accuracy = {}, loss = {}\".format(e, test_acc_mnist_torch, loss_mnist_torch))\n",
    "    loss_mnist_torch.backward()\n",
    "    optimizer_mnist_torch.step()\n",
    "    \n",
    "del nn\n",
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(loss_history_mnist, label='Custom DL framework')\n",
    "plt.plot(loss_history_mnist_torch, label='PyTorch')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
